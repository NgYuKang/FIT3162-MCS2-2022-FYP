{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81cedfbc",
   "metadata": {},
   "source": [
    "## FIT3162 Group MCS2 Model Training\n",
    "#### Import PyTorch and related stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e03c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, random_split, Subset, ConcatDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision import transforms, models\n",
    "from sklearn.metrics import classification_report\n",
    "from PIL import ImageFile\n",
    "from math import modf\n",
    "from CustomDataset import CustomDataset\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import time\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1fa3205",
   "metadata": {},
   "source": [
    "#### Select Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a0683a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90207648",
   "metadata": {},
   "source": [
    "#### Seed everything to try and make everything reproducible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684d7b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "os.environ['PYTHONHASHSEED'] = str(0)\n",
    "torch.cuda.manual_seed(0)\n",
    "torch.cuda.manual_seed_all(0)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e3249d",
   "metadata": {},
   "source": [
    "#### Init parameters and transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31878a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set training parameters\n",
    "BATCH_SIZE = 15 ## Change batch size as required, if when training there is not enough memory, decrease it,\n",
    "                            ## Else try to increase it and push it, bigger batch size, less epoch may be required to reach\n",
    "                            ## desired accuracy/diminishing return point\n",
    "PROCESSES = 8 ## Maximum is how much logical processors.\n",
    "EPOCHS = 10  \n",
    "\n",
    "# Initialize transformation\n",
    "transform = transforms.Compose([\n",
    "    # resize\n",
    "    transforms.Resize(256),\n",
    "    # center_crop\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.GaussianBlur(3, 1),\n",
    "    transforms.RandomGrayscale(0.1),\n",
    "    transforms.RandomHorizontalFlip(0.25),\n",
    "    transforms.RandomVerticalFlip(0.25),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.RandomErasing(p=0.4, scale=(0.02, 0.25)),\n",
    "    transforms.RandomApply(transforms=[transforms.RandomAffine(degrees=(-30, 30), translate=(0.1, 0.3),\n",
    "                                                               scale=(0.75, 0.95))], p=0.5),\n",
    "    transforms.Normalize(mean=[0.4704, 0.4565, 0.4425], std=[0.3045, 0.2898, 0.2999])\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    # resize\n",
    "    transforms.Resize(256),\n",
    "    # center_crop\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.GaussianBlur(3, 1),  # Remove noise\n",
    "    transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.4704, 0.4565, 0.4425], std=[0.3045, 0.2898, 0.2999])\n",
    "])\n",
    "\n",
    "transform_unnormalize = transforms.Compose([\n",
    "    transforms.Normalize(mean=[-0.4704 / 0.3045, -0.4565 / 0.2898, -0.4425 / 0.2999],\n",
    "                         std=[1.0 / 0.3045, 1.0 / 0.2898, 1.0 / 0.2999])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1338f3f4",
   "metadata": {},
   "source": [
    "### Get Dataset\n",
    "#### Original dataset -> get sub label for all images -> (magic bodge: built in function to go and get labels, which corresponds correctly)\n",
    "\n",
    "#### -> Split using sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23153daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# timing dataset preprocessing in case it takes too long in the future when dataset gets bloated\n",
    "start = time.time()\n",
    "print(f'Loading main dataset... ', end=\"\")\n",
    "labels_map = [\"Non Sports\", \"Sports\"]\n",
    "\n",
    "dataset = CustomDataset(root=\"./dataset\", transform=transform)\n",
    "dataset_test = CustomDataset(root=\"./dataset\", transform=transform_test)\n",
    "# Get sub classes in each category\n",
    "classes_sport = dataset.find_classes(dataset.root+\"/sport\")\n",
    "classes_non_sport = dataset.find_classes(dataset.root+\"/non sport\")\n",
    "# Combined classes\n",
    "both_combined =  classes_non_sport[0] + classes_sport[0]\n",
    "# Bodge to use built in function\n",
    "IMG_EXTENSIONS = (\".jpg\", \".jpeg\", \".png\", \".ppm\", \".bmp\", \".pgm\", \".tif\", \".tiff\", \".webp\")\n",
    "# Create labels for built in func\n",
    "\n",
    "non_sport_dict = {}\n",
    "for i in range(len(classes_non_sport[0])):\n",
    "    non_sport_dict[classes_non_sport[0][i]] = i\n",
    "\n",
    "sport_dict = {}\n",
    "for i in range(len(classes_non_sport[0]), len(classes_sport[0])+len(classes_non_sport[0])):\n",
    "    sport_dict[classes_sport[0][i-len(classes_non_sport[0])]] = i\n",
    "\n",
    "print(\"Done\\n\")\n",
    "    \n",
    "# Use build in function to get us labels, however it is inefficient because\n",
    "# it also recreates a whole new dataset variable...\n",
    "sports_temp = dataset.make_dataset(dataset.root+\"/sport\", sport_dict, IMG_EXTENSIONS, None)\n",
    "non_sports_temp = dataset.make_dataset(dataset.root+\"/non sport\", non_sport_dict, IMG_EXTENSIONS, None)\n",
    "# Retrieve the sub label \n",
    "# Must be non_sports first! A-Z!\n",
    "non_sports_label = [s[1] for s in non_sports_temp]\n",
    "sports_label = [s[1] for s in sports_temp]\n",
    "# Combine and add as attribute\n",
    "combined = non_sports_label + sports_label\n",
    "dataset.sub_labels = combined\n",
    "dataset_test.sub_labels = combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372b59ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Splitting into Train, Validation and Test sets... \", end=\"\")\n",
    "# Split into train, test and validation sets\n",
    "train_idx, test_idx, train_labels, test_labels = train_test_split(\n",
    "    np.arange(len(dataset.sub_labels)), dataset.sub_labels, test_size=0.2, random_state=42, shuffle=True, stratify=dataset.sub_labels)\n",
    "test_idx, valid_idx, test_labels, val_label = train_test_split(test_idx, test_labels, test_size=0.5, random_state=42, shuffle=True, stratify=test_labels)\n",
    "\n",
    "# Create the sets\n",
    "train_data = Subset(dataset, train_idx)\n",
    "test_data = Subset(dataset_test, test_idx)\n",
    "val_data = Subset(dataset_test, valid_idx)\n",
    "\n",
    "train_size = len(train_data)\n",
    "val_size = len(val_data)\n",
    "test_size = len(test_data)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, num_workers=PROCESSES , shuffle=True, pin_memory=True)\n",
    "test_loader = DataLoader(test_data, batch_size=BATCH_SIZE, num_workers=PROCESSES , shuffle=True, pin_memory=True)\n",
    "val_loader = DataLoader(val_data, batch_size=BATCH_SIZE, num_workers=PROCESSES , shuffle=True, pin_memory=True)\n",
    "\n",
    "runtime = time.time() - start\n",
    "seconds, minutes = modf(runtime/60)\n",
    "seconds *= 60\n",
    "\n",
    "print(f'Done\\n\\nDataset images    : {len(dataset)}')\n",
    "print(f'Train set         : {train_size} images, {train_size/len(dataset)*100}%')\n",
    "print(f'Validation set    : {val_size} images, {val_size/len(dataset)*100}%')\n",
    "print(f'Test set          : {test_size} images, {test_size/len(dataset)*100}%')\n",
    "print(f'Sum of split sets : {train_size+val_size+test_size} images\\n')\n",
    "print(f'Total time taken for dataset: {minutes:.0f} min {seconds:.2f} sec\\n-----------------------------\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80971e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "both_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4f4bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in both_combined:\n",
    "    print(i)\n",
    "print(f'\\nTotal sub labels: {len(both_combined)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f21228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count each class in original\n",
    "count_original = {classname: 0 for classname in range(len(both_combined))}\n",
    "for i in range(len(dataset)):\n",
    "    label = dataset.sub_labels[i]\n",
    "    count_original[label] += 1\n",
    "count_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ce652b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count each class in train\n",
    "count_train = {classname: 0 for classname in range(len(both_combined))}\n",
    "for each in train_idx:\n",
    "    label = dataset.sub_labels[each]\n",
    "    count_train[label] += 1\n",
    "count_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd16403c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise image to double check we have correct sublabel\n",
    "# We check validation set\n",
    "figure = plt.figure(figsize=(8, 8))\n",
    "cols, rows = 3, 3\n",
    "for i in range(1, cols * rows + 1):\n",
    "    sample_idx = torch.randint(val_size, size=(1,)).item()\n",
    "    img, label = val_data[sample_idx]\n",
    "    sublabel = val_label[sample_idx]\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.title(both_combined[sublabel])\n",
    "    plt.axis(\"off\")\n",
    "    img = transform_unnormalize(img)     # attempt to unnormalize...\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f601e9b",
   "metadata": {},
   "source": [
    "#### Visualize according to sports and non sports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d68377",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = plt.figure(figsize=(8, 8))\n",
    "cols, rows = 3, 3\n",
    "for i in range(1, cols * rows + 1):\n",
    "    sample_idx = torch.randint(train_size, size=(1,)).item()\n",
    "    img, label = train_data[sample_idx]\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.title(labels_map[label[\"main_label\"]])\n",
    "    plt.axis(\"off\")\n",
    "    img = transform_unnormalize(img)     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869aa4af",
   "metadata": {},
   "source": [
    "#### Set up model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d122fae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiOutputModel(nn.Module):\n",
    "\n",
    "    def __init__(self, n_main_classes, n_sub_classes):\n",
    "        super().__init__()\n",
    "        self.base_model = nn.Sequential(*list(models.resnet50(weights=\"ResNet50_Weights.DEFAULT\").children())[:-2])  # take the model without classifier\n",
    "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        # create separate classifiers for our outputs\n",
    "        #self.main_label = models.alexnet(weights='AlexNet_Weights.DEFAULT').classifier\n",
    "        self.main_label = nn.Linear(in_features=2048, out_features=n_main_classes)\n",
    "        #self.sub_label = models.alexnet(weights='AlexNet_Weights.DEFAULT').classifier\n",
    "        self.sub_label = nn.Linear(in_features=2048, out_features=n_sub_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.base_model(x)\n",
    "        x = self.pool(x)\n",
    "\n",
    "        # reshape from [batch, channels, 1, 1] to [batch, channels] to put it into classifier\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "\n",
    "        return {\n",
    "            'main_label': self.main_label(x),\n",
    "            'sub_label': self.sub_label(x),\n",
    "        }\n",
    "    \n",
    "    def get_loss(self, net_output, ground_truth):\n",
    "        main_loss = F.cross_entropy(net_output['main_label'], ground_truth['main_label'])\n",
    "        sub_loss = F.cross_entropy(net_output['sub_label'], ground_truth['sub_label'])\n",
    "        loss = main_loss + sub_loss\n",
    "        return loss, {'main_loss': main_loss, 'sub_loss': sub_loss}\n",
    "\n",
    "# Load Model\n",
    "model_ft = MultiOutputModel(2, len(both_combined))\n",
    "model_ft = model_ft.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75cde90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_device_dict(obj, device):\n",
    "    res = {}\n",
    "    for k, v in obj.items():\n",
    "      res[k] = v.to(device)\n",
    "    return res\n",
    "# Training information\n",
    "TRAIN_STAT = {\n",
    "    \"train_loss\": [],\n",
    "    \"train_acc\": [],\n",
    "    \"val_loss\": [],\n",
    "    \"val_acc\": []\n",
    "}\n",
    "optimizer = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.8) # Multiply learning rate by 0.8 every 2 epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073c5818",
   "metadata": {},
   "source": [
    "#### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522b3ebf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"Training model...\")\n",
    "start = time.time()\n",
    "\n",
    "for epoch in range(EPOCHS):  # loop over the training set multiple times\n",
    "    \n",
    "    print(f'\\n-----------------------------\\n\\nEPOCH: {epoch+1}/{EPOCHS}')\n",
    "    print('Current lr: {0}'.format(optimizer.param_groups[0]['lr']))\n",
    "    model_ft.train()\n",
    "    \n",
    "    # reset loss and correct values\n",
    "    train_loss = val_loss = 0.0\n",
    "    total_train_loss = total_val_loss = 0.0\n",
    "    train_correct = val_correct = 0.0\n",
    "    print('\\nTraining...')\n",
    "    \n",
    "    for i, data in enumerate(train_loader):\n",
    "        # get the inputs; data is a list of [inputs, labels]        \n",
    "        inputs, labels = data[0].to(device), data[1]\n",
    "        labels = to_device_dict(labels, device)\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        # make prediction and calculate train loss\n",
    "        outputs = model_ft(inputs)\n",
    "        loss, losses_by_class = model_ft.get_loss(outputs, labels)\n",
    "        \n",
    "        # forward + backward + optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # keep track of loss and correct statistics\n",
    "        train_loss += loss.item()\n",
    "        total_train_loss += loss.item() \n",
    "        train_correct += (outputs[\"main_label\"].argmax(1) == labels[\"main_label\"]).float().sum().item()\n",
    "        \n",
    "        if i % 20 == 19:    # print every 20 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {train_loss / 20:.10f}')\n",
    "            train_loss = 0.0\n",
    "        \n",
    "    print('\\nValidating...')\n",
    "    \n",
    "    # turn off gradient tracking and computation\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        model_ft.eval()\n",
    "        \n",
    "        for i, data in enumerate(val_loader):\n",
    "            # make predictions and calculate validation loss\n",
    "            inputs, labels = data[0].to(device), data[1]\n",
    "            labels = to_device_dict(labels, device)\n",
    "            outputs = model_ft(inputs)\n",
    "            loss, losses_by_class = model_ft.get_loss(outputs, labels)\n",
    "            \n",
    "            # keep track of loss and correct statistics\n",
    "            val_loss += loss.item()\n",
    "            total_val_loss += loss.item()\n",
    "            val_correct += (outputs[\"main_label\"].argmax(1) == labels[\"main_label\"]).float().sum().item()\n",
    "            \n",
    "            if i % 5 == 4:    # print every 5 mini-batches\n",
    "                print(f'[{epoch + 1}, {i + 1:5d}] loss: {val_loss / 5:.10f}')\n",
    "                val_loss = 0.0\n",
    "    \n",
    "    # calculate average loss at current epoch\n",
    "    avg_train_loss = total_train_loss / train_size\n",
    "    avg_val_loss = total_val_loss / val_size\n",
    "    \n",
    "    # calculate accuracy at current epoch\n",
    "    train_acc = (train_correct / train_size) * 100\n",
    "    val_acc = (val_correct / val_size) * 100\n",
    "    \n",
    "    # store statistics\n",
    "    TRAIN_STAT[\"train_loss\"].append(avg_train_loss)\n",
    "    TRAIN_STAT[\"train_acc\"].append(train_acc)\n",
    "    TRAIN_STAT[\"val_loss\"].append(avg_val_loss)\n",
    "    TRAIN_STAT[\"val_acc\"].append(val_acc)\n",
    "    \n",
    "    # print statistics of current epoch\n",
    "    print(f'\\nAverage Train loss: {avg_train_loss:.5f}, Train accuracy: {train_acc:.2f}%')\n",
    "    print(f'Average Validation loss: {avg_val_loss:5f}, Validation accuracy: {val_acc:.2f}%')\n",
    "    \n",
    "    #scheduler step\n",
    "    scheduler.step()\n",
    "\n",
    "# calculate total time taken for the training process\n",
    "runtime = time.time() - start\n",
    "seconds, minutes = modf(runtime/60)\n",
    "seconds *= 60\n",
    "print('\\n-----------------------------\\nFinished Training\\nTotal time taken for training: %d min %d sec' % (minutes, seconds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5249c896",
   "metadata": {},
   "source": [
    "#### Visualise training stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08bde1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"ggplot\")\n",
    "\n",
    "plt.figure(figsize = (12,5))\n",
    "plt.plot(TRAIN_STAT[\"train_acc\"], label=\"train_acc\")\n",
    "plt.plot(TRAIN_STAT[\"val_acc\"], label=\"val_acc\")\n",
    "plt.title(\"Training Accuracy on Dataset\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "\n",
    "plt.savefig('accuracy.png')\n",
    "\n",
    "plt.figure(figsize = (12,5))\n",
    "plt.plot(TRAIN_STAT[\"train_loss\"], label=\"train_loss\")\n",
    "plt.plot(TRAIN_STAT[\"val_loss\"], label=\"val_loss\")\n",
    "plt.title(\"Training Loss on Dataset\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "\n",
    "plt.savefig('loss.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2283353f",
   "metadata": {},
   "source": [
    "#### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac84314",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_scripted = torch.jit.script(model_ft) # Export to TorchScript\n",
    "model_scripted.save('resnet50_sports_non_sports_multilabel.pt') # Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3014a3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Testing model...\\n-----------------------------\")\n",
    "with torch.no_grad():\n",
    "    \n",
    "    model_ft.eval()\n",
    "    \n",
    "    predictions = []\n",
    "    actual = []\n",
    "    test_correct = 0\n",
    "    \n",
    "    for i, data in enumerate(test_loader):\n",
    "        # make predictions and add to list of predictions\n",
    "        inputs, labels = data[0].to(device), data[1]\n",
    "        main_label = labels[\"main_label\"]\n",
    "        outputs = model_ft(inputs)\n",
    "        output_main_label = outputs[\"main_label\"]\n",
    "        predictions.extend(output_main_label.argmax(axis=1).cpu().numpy())\n",
    "        actual.extend(main_label.cpu().numpy())\n",
    "        \n",
    "# print the results of the predictions in the form of a confusion matrix\n",
    "print(classification_report(np.array(predictions), np.array(actual), target_names=labels_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09001c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Testing model on sub-category...\\n-----------------------------\")\n",
    "with torch.no_grad():\n",
    "    \n",
    "    model_ft.eval()\n",
    "    \n",
    "    predictions = []\n",
    "    actual = []\n",
    "    test_correct = 0\n",
    "    \n",
    "    for i, data in enumerate(test_loader):\n",
    "        # make predictions and add to list of predictions\n",
    "        inputs, labels = data[0].to(device), data[1]\n",
    "        main_label = labels[\"sub_label\"]\n",
    "        outputs = model_ft(inputs)\n",
    "        output_main_label = outputs[\"sub_label\"]\n",
    "        predictions.extend(output_main_label.argmax(axis=1).cpu().numpy())\n",
    "        actual.extend(main_label.cpu().numpy())\n",
    "        \n",
    "# print the results of the predictions in the form of a confusion matrix\n",
    "print(classification_report(np.array(predictions), np.array(actual), target_names=both_combined))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a587d1",
   "metadata": {},
   "source": [
    "#### Visualize and intepret model\n",
    "#### Init values and related stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d683a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model = torch.jit.load('resnet50_sports_non_sports_multilabel.pt')\n",
    "model.to(device)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f558a577",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_resize = transforms.Compose([\n",
    "    # resize\n",
    "    transforms.Resize(256),\n",
    "    # center_crop\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.GaussianBlur(3, 1),  # Remove noise\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "transform_normalize = transforms.Compose([transforms.Normalize(mean=[0.4750, 0.4603, 0.4470], std=[0.3053, 0.2899, 0.2997])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af876a0",
   "metadata": {},
   "source": [
    "#### Load image and get predicted label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d982d857",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img_name = 'fake_injury_soccer.jpg'\n",
    "img = Image.open('test_images/'+img_name).convert('RGB')\n",
    "resized_img = transform_resize(img)\n",
    "transformed_img = transform_normalize(resized_img)\n",
    "input = transformed_img.unsqueeze(0)\n",
    "input = input.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ddabc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(input)\n",
    "main_label_output = F.softmax(output['main_label'], dim=1)\n",
    "sub_label_output = F.softmax(output['sub_label'], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07841652",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_score, pred_label_idx = torch.topk(main_label_output, 1)\n",
    "pred_label_main = labels_map[pred_label_idx.item()]\n",
    "\n",
    "prediction_score_sub, pred_label_idx_sub = torch.topk(sub_label_output, 1)\n",
    "pred_label_sub = both_combined[pred_label_idx_sub.item()]\n",
    "print(f'Testing image: \"{img_name}\"')\n",
    "print(f'Main label: {pred_label_main}, Sub label: {pred_label_sub}')\n",
    "print(f'Main label score: {prediction_score.item()*100:.2f}%, Sub label score: {prediction_score_sub.item()*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12131dc4",
   "metadata": {},
   "source": [
    "#### Import captum library, setup for model interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761f145a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from captum.attr import IntegratedGradients\n",
    "from captum.attr import LayerIntegratedGradients\n",
    "from captum.attr import GradientShap\n",
    "from captum.attr import Occlusion\n",
    "from captum.attr import NoiseTunnel\n",
    "from captum.attr import visualization as viz\n",
    "from captum.attr._utils.input_layer_wrapper import ModelInputWrapper\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "def wrapped_model(inp):\n",
    "    return model(inp)[\"main_label\"]\n",
    "\n",
    "def wrapped_model_sub(inp):\n",
    "    return model(inp)[\"sub_label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd06377",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_cmap = LinearSegmentedColormap.from_list('custom blue', \n",
    "                                                 [(0, '#ffffff'),\n",
    "                                                  (0.25, '#000000'),\n",
    "                                                  (1, '#000000')], N=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef382fa7",
   "metadata": {},
   "source": [
    "#### Visualise interpretation based on predicted label (main label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87fc031a",
   "metadata": {},
   "outputs": [],
   "source": [
    "integrated_gradients = IntegratedGradients(wrapped_model)\n",
    "noise_tunnel = NoiseTunnel(integrated_gradients)\n",
    "attributions_ig_nt = noise_tunnel.attribute(input, nt_samples=10, nt_type='smoothgrad_sq', target=pred_label_idx, nt_samples_batch_size=1)\n",
    "plt = viz.visualize_image_attr_multiple(np.transpose(attributions_ig_nt.squeeze().cpu().detach().numpy(), (1,2,0)),\n",
    "                                      np.transpose(resized_img.squeeze().cpu().detach().numpy(), (1,2,0)),\n",
    "                                      [\"original_image\", \"heat_map\"],\n",
    "                                      [\"all\", \"positive\"],\n",
    "                                      cmap=default_cmap,\n",
    "                                      show_colorbar=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d949cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt[0].savefig(\"result_intepret.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "023d1ca0",
   "metadata": {},
   "source": [
    "#### Visualise interpretation based on predicted label (sub label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b5c591",
   "metadata": {},
   "outputs": [],
   "source": [
    "integrated_gradients = IntegratedGradients(wrapped_model_sub)\n",
    "noise_tunnel = NoiseTunnel(integrated_gradients)\n",
    "attributions_ig_nt = noise_tunnel.attribute(input, nt_samples=10, nt_type='smoothgrad_sq', target=pred_label_idx_sub, nt_samples_batch_size=1)\n",
    "plt = viz.visualize_image_attr_multiple(np.transpose(attributions_ig_nt.squeeze().cpu().detach().numpy(), (1,2,0)),\n",
    "                                      np.transpose(resized_img.squeeze().cpu().detach().numpy(), (1,2,0)),\n",
    "                                      [\"original_image\", \"heat_map\"],\n",
    "                                      [\"all\", \"positive\"],\n",
    "                                      cmap=default_cmap,\n",
    "                                      show_colorbar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd192f4",
   "metadata": {},
   "source": [
    "#### Visualisation on our test data through Captum insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f1020e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from captum.insights import AttributionVisualizer, Batch\n",
    "from captum.insights.attr_vis.features import ImageFeature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bab6d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classes():\n",
    "    classes = ['Pedestrian', 'Queue', 'Reading', 'cello',\n",
    "               'driving', 'guitar', 'harp', 'using computer',\n",
    "               'violin', 'Badminton', 'Basketball', 'Cycling',\n",
    "               'Football', 'Tennis', 'squash']\n",
    "    return classes\n",
    "\n",
    "def get_classes_main():\n",
    "    classes = ['Non Sports', 'Sports']\n",
    "    return classes\n",
    "\n",
    "def get_pretrained_model():\n",
    "    model = torch.jit.load('resnet50_sports_non_sports_multilabel.pt')\n",
    "    model = model.cpu()\n",
    "    model.eval()\n",
    "    def wrapped_model_sub(inp):\n",
    "        return model(inp)[\"main_label\"]\n",
    "    return wrapped_model_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69fe8f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_func(input):\n",
    "    return input * 0\n",
    "\n",
    "\n",
    "def formatted_data_iter():\n",
    "    dataloader = iter(test_loader)\n",
    "    while True:\n",
    "        images, labels = next(dataloader)\n",
    "        yield Batch(inputs=images, labels=labels[\"main_bel\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a92b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize([0.4405, 0.4096, 0.3896], [0.3089, 0.2917, 0.2924])\n",
    "model = get_pretrained_model()\n",
    "visualizer = AttributionVisualizer(\n",
    "    models=[model],\n",
    "    score_func=lambda o: torch.nn.functional.softmax(o, 1),\n",
    "    classes=get_classes(),\n",
    "    features=[\n",
    "        ImageFeature(\n",
    "            \"Photo\",\n",
    "            baseline_transforms=[baseline_func],\n",
    "            input_transforms=[normalize],\n",
    "        )\n",
    "    ],\n",
    "    dataset=formatted_data_iter(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a82bb4",
   "metadata": {},
   "source": [
    "Run the cell below after running everything above which sets everything up\n",
    "to open Captum insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5bc039",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "visualizer.render()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "88279d2366fe020547cde40dd65aa0e3aa662a6ec1f3ca12d88834876c85e1a6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
